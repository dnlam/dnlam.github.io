---
layout: page
title: Publications
permalink: /projects/
---
<h2 id="thesis">Thesis</h2>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/5g_conni.jpg" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://theses.hal.science/tel-04141523"><b> [T] Centralised orchestration and hybrid resource management for Ultra Reliable and Low Latency Communications (URLLC)</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b>  5G Systems, Hybrid Resource Management, Lyapunov Optimization, Multi-Agent Reinforcement Learning, System Level Simulation.  </b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">Relying on Lyapunov’s optimizations for two-queue state system management, we design an optimization framework in which RAN latency, reliability and resource efficiency are considered. Afterwards, we implement an OpenAirInterface (OAI) testbed for the validation of our algorithms. This implementation step is a proof of their feasibility under real time restrictions, and this step illustrates performance of our algorithms in experimentation. Finally, we propose a novel hybrid Grant-Based (GB) and Grant-Free (GF) radio access scheme using Multi Agent Reinforcement Learning (MARL) for URLLC.
</span> </a> &nbsp; 
        <!-- <a href="https://www.photonics.com/Articles/CEA-Leti_Researchers_Set_Throughput_Record_for/a65854" class="label label-danger">Blog</a>  -->
        <a href="https://theses.hal.science/tel-04141523" class="label label-danger">Link</a>
  </div>
</div>

<h2 id="patents">Patents</h2>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/p1.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href=""><b> [P] Method to exploit latency distribution for early decision making, </b></a> <span style="font-size:16px;"><i>Patent 2103542, filled in March,2021 </i></span><br /> 
      <span style="font-size:15px;"><i><b> Early Decision Making.  </b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">The invention is concerned generally with wireless networks and in particular with a method and apparatus for orchestrating the execution of a plurality of mechanisms by one or more nodes in a wireless network.
</span> </a> &nbsp; 
        <!-- <a href="https://www.photonics.com/Articles/CEA-Leti_Researchers_Set_Throughput_Record_for/a65854" class="label label-danger">Blog</a>  -->
        <a href="https://www.leti-cea.fr/cea-tech/leti/Pages/Leti/Programmes-et-projets-soutenus/Liste-des-projets/5G-Conni.aspx" class="label label-danger">Link</a>
  </div>
</div>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/p2.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href=""><b> [P] Methods and apparatus for jitter-aware scheduling in wireless Time Sensitive Network communications, </b></a> <span style="font-size:16px;"><i>Patent 2103542, filled in May,2021 </i></span><br /> 
      <span style="font-size:15px;"><i><b> Network Determinism.</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">We introduce a jitter-aware orchestration method that forces latency to fall within predetermined windows.
</span> </a> &nbsp; 
        <!-- <a href="https://www.photonics.com/Articles/CEA-Leti_Researchers_Set_Throughput_Record_for/a65854" class="label label-danger">Blog</a>  -->
        <a href="https://www.leti-cea.fr/cea-tech/leti/Pages/Leti/Programmes-et-projets-soutenus/Liste-des-projets/5G-Conni.aspx" class="label label-danger">Link</a>
  </div>
</div>

<h2 id="journal">Journal articles</h2>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/5g_conni.jpg" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://jwcn-eurasipjournals.springeropen.com/articles/10.1186/s13638-021-02067-2"><b> [J] Beyond Private 5G  Networks: Applications, Architectures, Operator Models and Technological Enablers</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> 5G Network Architecture and Orchestration. </b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">Private networks will play a key role in 5G and beyond to enable smart factories with the required better deployment, operation and flexible usage of available resource and infrastructure. 5G private networks will offer a lean and agile solution to effectively deploy and operate services with stringent and heterogeneous constraints in terms of reliability, latency, re-configurability and re-deployment of resources as well as issues related to governance and ownership of 5G components, and elements. In this paper, we present a novel approach to operator models, specifically targeting 5G and beyond private networks. We apply the proposed operator models to different network architecture options and to a selection of relevant use cases offering mixed private–public network operator governance and ownership. Moreover, several key enabling technologies have been identified for 5G private networks. Before the deployment, stakeholders should consider spectrum allocation and on-site channel measurements in order to fully understand the propagation characteristic of a given environment and to set up end-to-end system parameters. During the deployment, a monitoring tools will support to validate the deployment and to make sure that the end-to-end system meet the target KPI. Finally, some optimization can be made individually for service placement, network slicing and orchestration or jointly at radio access, multi-access edge computing or core network level.
</span> </a> &nbsp; 
        <!-- <a href="https://www.photonics.com/Articles/CEA-Leti_Researchers_Set_Throughput_Record_for/a65854" class="label label-danger">Blog</a>  -->
        <a href="https://www.leti-cea.fr/cea-tech/leti/Pages/Leti/Programmes-et-projets-soutenus/Liste-des-projets/5G-Conni.aspx" class="label label-danger">Link</a>
  </div>
</div>

<h2 id="conf">Conference proceedings</h2>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/drl_cbf.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://arxiv.org/abs/2401.05525"><b>[C] Towards Safe Load Balancing based on Control Barrier Functions and Deep Reinforcement Learning
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> Network optimization, CUDA-enabled acceleration, Safety, Deep Reinforcement Learning (DRL), Control Barrier Function (CBF).</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">Deep Reinforcement Learning (DRL) algorithms have recently made significant strides in improving network performance. Nonetheless, their practical use is still limited in the absence of safe exploration and safe decision-making. In the context of commercial solutions, reliable and safe-to-operate systems are of paramount importance. Taking this problem into account, we propose a safe learning-based load balancing algorithm for Software Defined-Wide Area Network (SD-WAN), which is empowered by Deep Reinforcement Learning (DRL) combined with a Control Barrier Function (CBF). It safely projects unsafe actions into feasible ones during both training and testing, and it guides learning towards safe policies. We successfully implemented the solution on GPU to accelerate training by approximately 110x times and achieve model updates for on-policy methods within a few seconds, making the solution practical. We show that our approach delivers near-optimal Quality-of-Service (QoS) performance in terms of end-to-end delay while respecting safety requirements related to link capacity constraints. We also demonstrated that on-policy learning based on Proximal Policy Optimization (PPO) performs better than off-policy learning with Deep Deterministic Policy Gradient (DDPG) when both are combined with a CBF for safe load balancing. 
</span> </a> &nbsp; 
        <a href="https://arxiv.org/abs/2401.05525" class="label label-danger">Link</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/maddpg.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://ieeexplore.ieee.org/document/10188350"><b>[C] Hybrid Radio Resource Management Based on Multi-Agent Reinforcement Learning
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> Wireless optimization, Multi-Agent Deep Reinforcement Learning (MARL), System level simulation.</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">In this paper, we propose a novel hybrid grant-based and grant-free radio access scheme. We provide two multi-agent reinforcement learning algorithms to optimize a global network objective in terms of latency, reliability and network throughput: Multi-Agent Deep Q-Learning (MADQL) and Multi-Agent Deep Deterministic Policy Gradient (MADDPG). In MADQL, each user (agent) learns its optimal action-value function, which is based only on its local observation, and performs an optimal opportunistic action using the shared spectrum. MADDPG involves the attached gNB function as a global observer (critic), which criticizes the action of each associated agent (actor) in the network. By leveraging centralised training and decentralised execution, we achieve a shared goal better than the first algorithm. Then, through a system level simulation where the full protocol stack is considered, we show the gain of our approach to efficiently manage radio resources and guarantee latency.
</span> </a> &nbsp; 
        <a href="https://ieeexplore.ieee.org/document/10188350" class="label label-danger">Link</a> 
  </div>
</div>

<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/lyapunov.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://ieeexplore.ieee.org/abstract/document/9977893"><b>[C] Dynamic Resource Scheduling Optimization for Ultra-Reliable Low Latency Communications: From Simulation to Experimentation
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> Lyapunov optimization, System level simulation, Hardware experimentation.</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">In this paper, we propose a dynamic and efficient resource scheduling based on Lyapunov's optimization for Ultra-Reliable Low Latency Communications, taking into account the traffic arrival at the network layer, the queue behaviors at the data link layer and the risk that the applied decision might result in packet losses. The trade-off between the resource efficiency, latency and reliability is achieved by the timing and intensity of decisions and is adapted to dynamic scenarios (e.g., random bursty traffic, time-varying channel). Our queue-aware and channel-aware solution is evaluated in terms of latency, reliability outage and resource efficiency in a system-level simulator and validated by an experimental testbed using OpenAirInterface.
</span> </a> &nbsp; 
        <a href="https://ieeexplore.ieee.org/abstract/document/9977893" class="label label-danger">Link</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/lyapunov.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://ieeexplore.ieee.org/abstract/document/9815615"><b>[C] Towards URLLC with Proactive HARQ Adaptation
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> Lyapunov optimization, System level simulation.</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">In this work, we propose a dynamic decision maker algorithm to improve the proactive HARQ protocol for beyond 5G networks. Based on Lyapunov stochastic optimization, our adaptation control framework dynamically selects the number of proactive retransmissions for intermittent URLLC traffic scenarios under time-varying channel conditions without requiring any prior knowledge associated with this stochastic process. It then better exploits the trade-off between Radio Access Network (RAN) latency, reliability and resource efficiency, which is still limited in its realization on current HARQ designs. We then evaluate the performance of several HARQ strategies and show that our proposal further improves latency over the reactive regime without affecting the resource efficiency such as fixed proactive retransmission while maintaining target reliability.
</span> </a> &nbsp; 
        <a href="https://ieeexplore.ieee.org/abstract/document/9815615" class="label label-danger">Link</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/lyapunov.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://ieeexplore.ieee.org/abstract/document/9860872"><b>[C] Proactive Resource Scheduling for 5G and Beyond Ultra-Reliable Low Latency Communications
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> System level simulation.</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">Effective resource use in Ultra-Reliable and Low-Latency Communications (URLLC) is one of the main challenges for 5G and beyond systems. In this paper, we propose a novel scheduling methodology (combining reactive and proactive resource allocation strategies) specifically devised for URLLC services. Our ultimate objective is to characterize the level of proactivity required to cope with various scenarios. Specifically, we propose to operate at the scheduling level, addressing the trade-off between reliability, latency and resource efficiency. We offer an evaluation of the proposed methodology in the case of the well-known Hybrid Automatic Repeat reQuest (HARQ) protocol in which the proactive strategy allows a number of parallel retransmissions instead of the ‘'send-wait-react’' mode. To this end, we propose some deviations from the HARQ procedure and benchmark the performance in terms of latency, reliability outage and resource efficiency as a function of the level of proactivity. Afterwards, we highlight the critical importance of proactive adaptation in dynamic scenarios (i.e. with changing traffic rates and channel conditions).
</span> </a> &nbsp; 
        <a href="https://ieeexplore.ieee.org/abstract/document/9860872" class="label label-danger">Link</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/v2n.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://ieeexplore.ieee.org/abstract/document/9861012"><b>[C] Evaluation of 5G-NR V2N Connectivity in a Centralized Cooperative Lane Change Scenario
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> 5G-NR, Vehicular Networks, System level simulation.</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">By means of system-level simulations, we analyze in this paper the performance of Vehicle-to-Network (V2N) connectivity based on the 5th Generation - New Radio (5GNR) as a support to Cooperative, Connected and Automated Mobility (CCAM), in light of both network and Multi-access Edge Computing (MEC) deployments. Focusing on a canonical centralized Cooperative Lane Change (CLC) use case that involves three vehicles in a cross-border highway environment, we assess the link reliability and the End-to-End (E2E) latency of all the messages involved in the CLC negotiation phase (from/to interconnected MECs hosting the centralized maneuvering application), while assuming different deployment configurations and the coexistence with a second demanding vehicular service running over the same radio resources. On this occasion, we illustrate possible benefits from Bandwidth Partitioning (BWP) on Uplink (UL) latency, as well as from an hypothetically tight cooperation between Mobile Network Operators (MNOs) on reliability and continuity, leveraging low-latency inter-MEC transactions and seamless cross-border handover capabilities.
</span> </a> &nbsp; 
        <a href="https://ieeexplore.ieee.org/abstract/document/9861012" class="label label-danger">Link</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/Lifi_Communication.jpg" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://www.owcconference.com/paper/reaching-7-7-gb-s-in-owc-with-dco-ofdm-on-a-single-blue-10-%C2%B5m-gan-micro-led/"><b>[C] Reaching 7.7 Gb/s in OWC with DCO-OFDM on a Single Blue 10-um GaN Micro-LED
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i><b> Optical-Digital Signal Processing, micro-LED characterization</b></i></span> <br /> 
      <a class="label label-info"> Abstract <span class="abstract">This presentation describes recent activities on ultra-high speed Optical Wireless Communications (OWC) using Gallium-Nitride micro-LEDs designed and fabricated at CEA-Leti. Micro-LEDs are one of the most promising OWC optical sources due to their high illumination efficiency and their large modulation bandwidths. Preliminary work focused on the implementation of a 10-µm single blue micro-LED on sapphire wafer within an experimental OWC setup, mixing software generation of direct-current optical orthogonal frequency division multiplexing (DCO-OFDM) patterns and hardware optical components for light collection, high speed photo-detection and digital acquisitions. Intensity modulation conveys DCO-OFDM waveform and direct detection is used at reception. A high current density of 25.5 kA/cm² provided a modulation bandwidth of 1.8 GHz. Associated to bit and power loading with up to a 256-QAM subcarrier modulation, it enabled a new data rate of 7.7 Gb/s, compared to the previous record of 5.37 Gb/s reached with a blue 21-µm microLED in 2016. Towards a better understanding of the micro-LED design impact on OWC performance, next investigations will study the electrical modelling of such micro-LEDs in the high frequency regime. Future works will cover the use of large arrays of more than 10 thousands micro-LEDs. The first objective is to open the way to new digital-to-optical modulations by independently driving each pixel, to remove digital-to-analogue converter and target highly integrated system-on-chips for ultra-high speed OWC transmitters. Secondly, higher emitted optical power is expected to open such technology to indoor multiple access applications where light collection and emitter-receiver alignment may not be possible anymore.
</span> </a> &nbsp; 
        <a href="https://www.leti-cea.com/cea-tech/leti/english/Pages/What's-On/Press%20release/CEA-Leti-Researchers-Break-Throughput-Record-for-LiFi-Communications-Using-Single-GaN-Blue-Micro-Light-Emitting-Diode.aspx" class="label label-danger">Link</a> 
        <a href="https://www.photonics.com/Articles/CEA-Leti_Researchers_Set_Throughput_Record_for/a65854" class="label label-warning">News</a>
  </div>
</div>

<hr />


<h1 id="Pub">Certificates</h1>
<hr />
<h2 id="conf">Intellectual Property</h2>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/c1.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://nx23410.your-storageshare.de/s/NwA8yqQZ4F3nzee"><b>[C1] Intégrer La Propriété Industrielle Dans Son Activité Professionnelle
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i>
</i></span> <br /> 
      <a class="label label-info"> About  <span class="abstract">In this formation, we studied what is intellectual property, what is a patent and how to depot a patent.
</span> </a> &nbsp; 
        <a href="https://nx23410.your-storageshare.de/s/NwA8yqQZ4F3nzee" class="label label-success">Certificate</a> 
  </div>
</div>

<hr />
<h2 id="conf">Deep Learning</h2>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/f1.PNG" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://www.coursera.org/account/accomplishments/certificate/SXEAV9FX9Q7M"><b>[C2] Neural Networks and Deep Learning
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i>
</i></span> <br /> 
      <a class="label label-info"> About  <span class="abstract">In this course, we studied the foundational concept of neural networks and deep learning. By the end, we was familiar with the significant technological trends driving the rise of deep learning; build, train, and apply fully connected deep neural networks; implement efficient (vectorized) neural networks; identify key parameters in a neural network’s architecture; and apply deep learning to your own applications.
</span> </a> &nbsp; 
        <a href="https://www.coursera.org/account/accomplishments/certificate/SXEAV9FX9Q7M" class="label label-success">Certificate</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/f2.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://www.coursera.org/account/accomplishments/certificate/PSBN4VY96XLD"><b>[C3] Improving Deep Neural Networks: Hyperparameter Tuning, Regularization and Optimization
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i>
</i></span> <br /> 
      <a class="label label-info"> About  <span class="abstract">In the second course of the Deep Learning Specialization, we opened the deep learning black box to understand the processes that drive performance and generate good results systematically. By the end, we learned the best practices to train and develop test sets and analyze bias/variance for building deep learning applications; be able to use standard neural network techniques such as initialization, L2 and dropout regularization, hyperparameter tuning, batch normalization, and gradient checking; implement and apply a variety of optimization algorithms, such as mini-batch gradient descent, Momentum, RMSprop and Adam, and check for their convergence; and implement a neural network in TensorFlow.
</span> </a> &nbsp; 
        <a href="https://www.coursera.org/account/accomplishments/certificate/PSBN4VY96XLD" class="label label-success">Certificate</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/edx1.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://courses.edx.org/certificates/e5391e79663840f2bb5dbb8865856109"><b>[C4] Machine Learning with Python - From Linear Models to Deep Learning
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i>
</i></span> <br /> 
      <a class="label label-info"> About  <span class="abstract">In this course, we learned: (1) the principles behind machine learning problems such as classification, regression, clustering, and reinforcement learning, (2) Implement and analyze models such as linear models, kernel machines, neural networks, and graphical models, (3) Choose suitable models for different applications and (4) Implement and organize machine learning projects, from training, validation, parameter tuning, to feature engineering.
      </span> </a> &nbsp;
        <a href="https://courses.edx.org/certificates/e5391e79663840f2bb5dbb8865856109" class="label label-success">Certificate</a> 
  </div>
</div>

<hr />
<h2 id="conf">Reinforcement Learning</h2>
<hr />
<div class="row">
    <div class="paper-img">
      <img src="/images/papers/rl1.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://www.coursera.org/account/accomplishments/certificate/9NHWHJFTRZEZ"><b>[C5] Reinforcement Learning
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i>
</i></span> <br /> 
      <a class="label label-info"> About  <span class="abstract">This course introduced the fundamentals of Reinforcement Learning including: (1) Formalize problems as Markov Decision Processes, (2) Understand basic exploration methods and the exploration/exploitation tradeoff, (3) Understand value functions, as a general-purpose tool for optimal decision-making and (4) Know how to implement dynamic programming as an efficient solution approach to an industrial control problem.
</span> </a> &nbsp; 
        <a href="https://www.coursera.org/account/accomplishments/certificate/9NHWHJFTRZEZ" class="label label-success">Certificate</a> 
        <!-- <a href="https://www.photonics.com/Articles/CEA-Leti_Researchers_Set_Throughput_Record_for/a65854" class="label label-warning">News</a> -->
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/rl2.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://www.coursera.org/account/accomplishments/certificate/EEEXTWABZ3QP"><b>[C6] Sample-based Learning Methods
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i>
</i></span> <br /> 
      <a class="label label-info"> About  <span class="abstract">In this course, we shed light on several algorithms that can learn near optimal policies based on trial and error interaction with the environment. Learning from actual experience is striking because it requires no prior knowledge of the environment’s dynamics, yet can still attain optimal behavior. We covered intuitively simple but powerful Monte Carlo methods, and temporal difference learning methods including Q-learning. We wrapped up this course investigating how we can get the best of both worlds: algorithms that can combine model-based planning (similar to dynamic programming) and temporal difference updates to radically accelerate learning.
</span> </a> &nbsp; 
        <a href="https://www.coursera.org/account/accomplishments/certificate/EEEXTWABZ3QP" class="label label-success">Certificate</a> 
  </div>
</div>

<hr />

<div class="row">
    <div class="paper-img">
      <img src="/images/papers/rl3.png" class="thumbnail" width="200" height="200" />
    </div>
    <div class="paper-text">
      <a href="https://www.coursera.org/account/accomplishments/certificate/MSLWZ9ZCWKF8"><b>[C7] Prediction and Control with Function Approximation
</b></a> <span style="font-size:16px;"><i></i></span><br /> 
      <span style="font-size:15px;"><i>
</i></span> <br /> 
      <a class="label label-info"> About  <span class="abstract">In this course, we learned how to solve problems with large, high-dimensional, and potentially infinite state spaces. We studied that estimating value functions can be cast as a supervised learning problem (function approximation) allowing you to build agents that carefully balance generalization and discrimination in order to maximize reward. We begun this journey by investigating how our policy evaluation or prediction methods like Monte Carlo and TD can be extended to the function approximation setting. We learned about feature construction techniques for RL, and representation learning via neural networks and backprop. We concluded this course with a deep-dive into policy gradient methods; a way to learn policies directly without learning a value function. In this course we solved two continuous-state control tasks and investigate the benefits of policy gradient methods in a continuous-action environment. 
</span> </a> &nbsp; 
        <a href="https://www.coursera.org/account/accomplishments/certificate/MSLWZ9ZCWKF8" class="label label-success">Certificate</a> 
  </div>
</div>

<hr />